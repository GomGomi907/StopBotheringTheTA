import json
import logging
from pathlib import Path
from typing import List, Dict, Any
from collections import defaultdict
import asyncio

from src.config.settings import Settings
from src.llm.client import LLMClient
from src.processing.metadata import MetadataExtractor

logger = logging.getLogger(__name__)

class DataRefiner:
    def __init__(self):
        self.settings = Settings.from_env()
        self.client = LLMClient()
        self.extractor = MetadataExtractor()
        self.kb_path = Path("data/knowledge_base.json")
        
    def load_raw_data(self) -> Dict[str, List[Dict]]:
        """record.jsonlì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê³¼ëª©ë³„ë¡œ ê·¸ë£¹í™”"""
        records_path = self.settings.raw_records_dir / "records.jsonl"
        if not records_path.exists():
            return {}

        grouped_data = defaultdict(list)
        
        with open(records_path, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    rec = json.loads(line)
                    # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (Title, Date, URL ë“± 1ì°¨ ê°€ê³µ)
                    meta = self.extractor.summarize_record(rec)
                    
                    # ê³¼ëª© ID/ì´ë¦„ ë§¤í•‘
                    payload = rec.get("payload", {})
                    cid = "common"
                    cname = "ì¼ë°˜ ê³µì§€"
                    
                    if isinstance(payload, dict):
                        cid = str(payload.get("course_id", "common"))
                    
                    # íƒœê·¸ ê¸°ë°˜ í´ë°±
                    tags = rec.get("tags", [])
                    if cid == "common" and len(tags) > 1:
                        cid = tags[1]
                        
                    # ê³¼ëª©ëª… (rec.titleì€ í˜ì´ì§€ íƒ€ì´í‹€ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜)
                    if rec.get("category") == "course":
                        # ì½”ìŠ¤ ì •ë³´ ë ˆì½”ë“œì—ì„œ ê³¼ëª©ëª… ì¶”ì¶œ
                        pass 
                    
                    # ë©”íƒ€ë°ì´í„°ì— ì›ë³¸ ID ì£¼ì… (ì¤‘ë³µ ë°©ì§€ìš©)
                    meta["original_id"] = f"{cid}_{meta['url']}"
                    meta["course_id"] = cid
                    # meta["course_name"]ì€ ë‚˜ì¤‘ì— ë§¤í•‘
                    
                    grouped_data[cid].append(meta)
                except Exception:
                    continue
                    
        return grouped_data

    def run_refinement(self, course_names: Dict[str, str]):
        """ETL ì‹¤í–‰: Raw Data -> LLM Refinement -> Knowledge Base"""
        raw_grouped = self.load_raw_data()
        knowledge_base = []
        
        total_courses = len(raw_grouped)
        print(f"ğŸš€ [Refiner] {total_courses}ê°œ ê³¼ëª© ë°ì´í„° ì •ì œ ì‹œì‘...")

        for cid, items in raw_grouped.items():
            c_name = course_names.get(str(cid), f"Course {cid}")
            if c_name == "common": c_name = "ì¼ë°˜ ê³µì§€"
            
            print(f"  - Processing {c_name} ({len(items)} items)...")
            
            # Chunking (LLM Context Limit ê³ ë ¤, 10ê°œì”©)
            chunk_size = 10
            for i in range(0, len(items), chunk_size):
                chunk = items[i:i+chunk_size]
                
                # LLM í˜¸ì¶œ
                refined_chunk = self.client.refine_chunk(c_name, chunk)
                
                # ê²°ê³¼ ë³‘í•©
                for item in refined_chunk:
                    item["course_name"] = c_name
                    item["course_id"] = cid
                    knowledge_base.append(item)
                    
        # ì €ì¥
        with open(self.kb_path, "w", encoding="utf-8") as f:
            json.dump(knowledge_base, f, ensure_ascii=False, indent=2)
            
        print(f"âœ… [Refiner] ì •ì œ ì™„ë£Œ! {len(knowledge_base)}ê°œ í•­ëª© ì €ì¥ë¨: {self.kb_path}")
        return knowledge_base

if __name__ == "__main__":
    # Test Runner
    # (ì‹¤ì œ ì‹¤í–‰ ì‹œì—ëŠ” dashboard.py ë“±ì—ì„œ course_namesë¥¼ ë„˜ê²¨ë°›ì•„ì•¼ í•¨)
    # ì—¬ê¸°ì„œëŠ” ì„ì‹œ í…ŒìŠ¤íŠ¸ìš©
    refiner = DataRefiner()
    # ì„ì‹œ ì½”ìŠ¤ëª… ë§µ (í…ŒìŠ¤íŠ¸ìš©)
    test_map = {} 
    refiner.run_refinement(test_map)
